@article{joffe_optimized_2013,
 abstract = {Clinical databases may contain several records for a single patient. Multiple general entity-resolution algorithms have been developed to identify such duplicate records. To achieve optimal accuracy, algorithm parameters must be tuned to a particular dataset. The purpose of this study was to determine the required training set size for probabilistic, deterministic and Fuzzy Inference Engine (FIE) algorithms with parameters optimized using the particle swarm approach. Each algorithm classified potential duplicates into: definite match, non-match and indeterminate (i.e., requires manual review). Training sets size ranged from 2,000-10,000 randomly selected record-pairs. We also evaluated marginal uncertainty sampling for active learning. Optimization reduced manual review size (Deterministic 11.6% vs. 2.5%; FIE 49.6% vs. 1.9%; and Probabilistic 10.5% vs. 3.5%). FIE classified 98.1% of the records correctly (precision=1.0). Best performance required training on all 10,000 randomly-selected record-pairs. Active learning achieved comparable results with 3,000 records. Automated optimization is effective and targeted sampling can reduce the required training set size.},
 author = {Joffe, Erel and Byrne, Michael J. and Reeder, Phillip and Herskovic, Jorge R. and Johnson, Craig W. and McCoy, Allison B. and Bernstam, Elmer V.},
 issn = {1942-597X},
 journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
 keywords = {Algorithms, Artificial Intelligence, Electronic Health Records, Fuzzy Logic},
 language = {eng},
 pages = {721--730},
 pmcid = {PMC3900213},
 pmid = {24551372},
 title = {Optimized dual threshold entity resolution for electronic health record databases--training set size and active learning},
 volume = {2013},
 year = {2013}
}
